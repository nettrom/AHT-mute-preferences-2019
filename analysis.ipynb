{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "from wmfdata import hive, mariadb\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "\n",
    "wikis = ['enwiki', 'frwiki', 'dewiki', 'eswiki', 'ruwiki',\n",
    "         'itwiki', 'nlwiki', 'jawiki', 'zhwiki', 'ptwiki']\n",
    "\n",
    "start_time = dt.datetime(2017, 1, 1, 0, 0, 0)\n",
    "end_time = dt.datetime(2019, 3, 1, 0, 0, 0)\n",
    "\n",
    "## Start time for the monthly count of users who add their first name to the Echo blacklist\n",
    "## is moved to 2018-01-01 to remove a spike in usage in late 2017, as we are more interested\n",
    "## more recent development as well as changes over time (which the spike hides). See also notes below.\n",
    "## This is set as a string so it can be used in R.\n",
    "echo_start_time = \"2018-01-01\"\n",
    "\n",
    "## Name of the log databases for preference modifications:\n",
    "log_tables = ['PrefUpdate_5563398_15423246', 'PrefUpdate_5563398']\n",
    "\n",
    "## Format strings:\n",
    "## MediaWiki database timestamp format\n",
    "mw_format = \"%Y%m%d%H%M%S\"\n",
    "\n",
    "## Standard format on timestamps in the Data Lake\n",
    "hive_format = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "## Graphs go into the \"graphs/\" folder\n",
    "graph_folder = \"graphs/\"\n",
    "\n",
    "## Graph suffix (always \".png\" for now)\n",
    "graph_suffix = \".png\"\n",
    "\n",
    "## Prefixes for all graphs, will have \"_\", the wiki db name, and the suffix appended to it.\n",
    "## Titles for all graphs will have the wiki db name appended to it\n",
    "disablemail_graph = \"disablemail_monthly\"\n",
    "disablemail_title = \"Monthly count of users disabling email - \"\n",
    "\n",
    "newuser_email_graph = \"disable_newuser_email_monthly\"\n",
    "newuser_title = \"Monthly count of users disabling email from brand-new users - \"\n",
    "\n",
    "email_blocklist_graph = \"email_blocklist_initial_users_monthly\"\n",
    "email_blocklist_title = \"Monthly count of users adding first name to email blacklist - \"\n",
    "\n",
    "echo_blocklist_graph = \"notification_blocklist_initial_users_monthly\"\n",
    "echo_blocklist_title = \"Monthly count of users adding first name to notification blacklist - \"\n",
    "\n",
    "email_usage_graph = \"email_blocklist_histogram\"\n",
    "email_usage_title = \"Number of users on email blacklist - \"\n",
    "\n",
    "echo_usage_graph = \"echo_blocklist_histogram\"\n",
    "echo_usage_title = \"Number of users on Echo notifications blacklist - \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nettrom/venv/lib/python3.5/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: data.table 1.11.8  Latest news: r-datatable.com\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(data.table);\n",
    "library(ggplot2);\n",
    "library(tidyr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second function needs dnspython to work\n",
    "import dns.resolver\n",
    "import glob\n",
    "\n",
    "def get_mediawiki_section_dbname_mapping(mw_config_path, use_x1):\n",
    "    db_mapping = {}\n",
    "    if use_x1:\n",
    "        dblist_section_paths = [mw_config_path.rstrip('/') + '/dblists/all.dblist']\n",
    "    else:\n",
    "        dblist_section_paths = glob.glob(mw_config_path.rstrip('/') + '/dblists/s[0-9]*.dblist')\n",
    "    for dblist_section_path in dblist_section_paths:\n",
    "        with open(dblist_section_path, 'r') as f:\n",
    "            for db in f.readlines():\n",
    "                db_mapping[db.strip()] = dblist_section_path.strip().rstrip('.dblist').split('/')[-1]\n",
    "\n",
    "    return db_mapping\n",
    "\n",
    "\n",
    "def get_dbstore_host_port(db_mapping, use_x1, dbname):\n",
    "    if dbname == 'staging':\n",
    "        shard = 'staging'\n",
    "    elif use_x1:\n",
    "        shard = 'x1'\n",
    "    else:\n",
    "        try:\n",
    "            shard = db_mapping[dbname]\n",
    "        except KeyError:\n",
    "            raise RuntimeError(\"The database {} is not listed among the dblist files of the supported sections.\"\n",
    "                               .format(dbname))\n",
    "    answers = dns.resolver.query('_' + shard + '-analytics._tcp.eqiad.wmnet', 'SRV')\n",
    "    host, port = str(answers[0].target), answers[0].port\n",
    "    return (host,port)\n",
    "\n",
    "wikidb_map = get_mediawiki_section_dbname_mapping('/srv/mediawiki-config', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users turning off email\n",
    "\n",
    "I'll interpret this statistics so as to mean we count whenever a user changes the \"disablemail\" preference to \"true\". Thus, if a user at some point decides to turn it off and on again, we'll count them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "disablemail_query = '''\n",
    "SELECT log_date, wiki, SUM(num_events) AS num_events\n",
    "FROM ((\n",
    "SELECT DATE_FORMAT(timestamp, '%Y-%m-01') AS log_date,\n",
    "       wiki,\n",
    "       COUNT(*) AS num_events\n",
    "FROM log.{tables[0]}\n",
    "WHERE timestamp >= \"{start_timestamp}\"\n",
    "AND timestamp < \"{end_timestamp}\"\n",
    "AND wiki IN ({wiki_list})\n",
    "AND event_property = \"{prop}\"\n",
    "AND event_value = \"{value}\"\n",
    "GROUP BY log_date, wiki\n",
    ")\n",
    "UNION ALL\n",
    "(\n",
    "SELECT DATE_FORMAT(timestamp, '%Y-%m-01') AS log_date,\n",
    "       wiki,\n",
    "       COUNT(*) AS num_events\n",
    "FROM log.{tables[1]}\n",
    "WHERE timestamp >= \"{start_timestamp}\"\n",
    "AND timestamp < \"{end_timestamp}\"\n",
    "AND wiki IN ({wiki_list})\n",
    "AND event_property = \"{prop}\"\n",
    "AND event_value = \"{value}\"\n",
    "GROUP BY log_date, wiki\n",
    ")) AS e\n",
    "GROUP BY log_date, wiki\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "disablemail_counts = mariadb.run(disablemail_query.format(\n",
    "    prop = \"disablemail\",\n",
    "    value = \"true\",\n",
    "    tables = log_tables,\n",
    "    start_timestamp = start_time.strftime(mw_format),\n",
    "    end_timestamp = end_time.strftime(mw_format),\n",
    "    wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis])\n",
    "    ), host='logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_date</th>\n",
       "      <th>wiki</th>\n",
       "      <th>num_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>dewiki</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>enwiki</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>eswiki</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>frwiki</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>itwiki</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>jawiki</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>nlwiki</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>ptwiki</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>ruwiki</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>zhwiki</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_date    wiki  num_events\n",
       "250  2019-02-01  dewiki        88.0\n",
       "251  2019-02-01  enwiki       545.0\n",
       "252  2019-02-01  eswiki        44.0\n",
       "253  2019-02-01  frwiki        25.0\n",
       "254  2019-02-01  itwiki        32.0\n",
       "255  2019-02-01  jawiki        45.0\n",
       "256  2019-02-01  nlwiki        14.0\n",
       "257  2019-02-01  ptwiki        14.0\n",
       "258  2019-02-01  ruwiki        66.0\n",
       "259  2019-02-01  zhwiki        52.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disablemail_counts.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "make_graphs = function(dt, wikis, title, filename, graph_dir, graph_suffix) {\n",
    "    graphs = c()\n",
    "    for(w in wikis) {\n",
    "        g = ggplot(dt[wiki == w], aes(x = log_date, y = num_events)) +\n",
    "        scale_x_date(date_breaks = \"3 months\", date_minor_breaks = \"1 month\",\n",
    "                     date_labels = \"%Y-%m\") +\n",
    "        expand_limits(y = 0) +\n",
    "        labs(title = paste0(title, w),\n",
    "             x = 'Date',\n",
    "             y = 'Count') +\n",
    "        theme_light(base_size = 14) +\n",
    "        geom_line();\n",
    "        ggsave(paste0(graph_dir, filename, '_', w, graph_suffix),\n",
    "               plot = g, width = 30, height = 20, units = \"cm\", dpi = \"screen\");\n",
    "        graphs = append(graphs, g);\n",
    "    }\n",
    "    graphs;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i disablemail_counts,wikis,disablemail_title,disablemail_graph,graph_folder,graph_suffix\n",
    "\n",
    "disablemail_counts = data.table(disablemail_counts);\n",
    "disablemail_counts[, log_date := as.Date(log_date)];\n",
    "\n",
    "graphs = make_graphs(disablemail_counts, wikis, disablemail_title, disablemail_graph,\n",
    "            graph_folder, graph_suffix);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users turning off email from brand new users\n",
    "\n",
    "Similarly as for users disabling email (in general), I'll interpret this to mean the count of number of users who change this preference, again meaning that someone who turns it off and on again will be counted again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "disablenew_counts = mariadb.run(disablemail_query.format(\n",
    "    prop = \"email-allow-new-users\",\n",
    "    value = \"false\",\n",
    "    tables = log_tables,\n",
    "    start_timestamp = start_time.strftime(mw_format),\n",
    "    end_timestamp = end_time.strftime(mw_format),\n",
    "    wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis])\n",
    "    ), host='logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i disablenew_counts,wikis,newuser_title,newuser_email_graph,graph_folder,graph_suffix\n",
    "\n",
    "disablenew_counts = data.table(disablenew_counts);\n",
    "disablenew_counts[, log_date := as.Date(log_date)];\n",
    "\n",
    "dates = seq.Date(min(disablenew_counts$log_date), max(disablenew_counts$log_date), by='month');\n",
    "dates = data.table(log_date = dates);\n",
    "\n",
    "# disablenew_counts = disablenew_counts[dates, on = 'log_date'];\n",
    "\n",
    "graphs = make_graphs(disablenew_counts, wikis, newuser_title, newuser_email_graph,\n",
    "            graph_folder, graph_suffix);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users who add their first user to the email block list\n",
    "\n",
    "I'll interpret this to mean the first recorded timestamp of a given user setting their email block list to something that isn't empty. This leads to an expectancy problem, in that if we only look at events from `start_time`, we'll likely pick up experienced users just updating the list (rather than starting it). There's several ways we can remedy that problem, here are a couple:\n",
    "\n",
    "1. Start our data gathering earlier than `start_time`, and filter out users who updated the list.\n",
    "2. Migrate to the Data Lake and use the `mediawiki_user_history` table to identify when users registered and only count certain groups of users (e.g. users have to initalize the list within some time after registration).\n",
    "\n",
    "In this case, we'll start with the first approach and gather data for a year prior to `start_time`, and remove those from the calculation. A year should be a decent amount of time to allow someone to start using the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_blacklist_query = '''\n",
    "SELECT wiki,\n",
    "       DATE_FORMAT(first_event, \"%Y-%m-01\") AS log_date,\n",
    "       COUNT(*) AS num_events\n",
    "FROM (SELECT wiki, user_id, MIN(timestamp) AS first_event\n",
    "      FROM ((\n",
    "        SELECT wiki,\n",
    "               event_userid AS user_id,\n",
    "               MIN(timestamp COLLATE utf8_unicode_ci) AS timestamp\n",
    "        FROM log.{tables[0]}\n",
    "        WHERE timestamp >= \"{data_timestamp}\"\n",
    "        AND timestamp < \"{end_timestamp}\"\n",
    "        AND wiki IN ({wiki_list})\n",
    "        AND event_property = \"email-blacklist\"\n",
    "        AND event_value != \"null\"\n",
    "        AND event_value != '\"0\"'\n",
    "        AND event_value != '\"\"'\n",
    "        GROUP BY wiki, user_id\n",
    "    )\n",
    "    UNION ALL\n",
    "    (\n",
    "        SELECT wiki,\n",
    "               event_userid AS user_id,\n",
    "               MIN(timestamp) AS timestamp\n",
    "        FROM log.{tables[1]}\n",
    "        WHERE timestamp >= \"{data_timestamp}\"\n",
    "        AND timestamp < \"{end_timestamp}\"\n",
    "        AND wiki IN ({wiki_list})\n",
    "        AND event_property = \"email-blacklist\"\n",
    "        AND event_value != \"null\"\n",
    "        AND event_value != '\"0\"'\n",
    "        AND event_value != '\"\"'\n",
    "        GROUP BY wiki, user_id\n",
    "    )) AS e\n",
    "    GROUP BY wiki, user_id) AS ev\n",
    "WHERE first_event >= \"{start_timestamp}\"\n",
    "AND first_event < \"{end_timestamp}\"\n",
    "GROUP BY wiki, log_date\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soâ€¦ digging into this, I've found lots of duplicate events in the database. For example, one user has 4,588 events logged in the first three months of 2018, and in the first 100 of them there are lots of pairs of events with the same timestamp in the database but different save timestamps, and where the value of the blacklist doesn't change.\n",
    "\n",
    "This means that my approach of using the first timestamp might just be working. It also means that there is no straightforward way of measuring usage of this feature (i.e. count of users modifying it) as it'll require deduplication.\n",
    "\n",
    "I've also looked into whether this is an issue for the `disablemail` (turning it on) and `email-allow-new-users` settings (turning it off) for the same three-month period, and did there not find any discrepancies. The user with the most number of events had 3, the rest of the top 25 had 2, which seems perfectly reasonable over that time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_blacklists = mariadb.run(email_blacklist_query.format(\n",
    "    tables = log_tables,\n",
    "    data_timestamp = start_time.replace(year=start_time.year-1).strftime(mw_format),\n",
    "    start_timestamp = start_time.strftime(mw_format),\n",
    "    end_timestamp = end_time.strftime(mw_format),\n",
    "    wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis])\n",
    "    ), host='logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i email_blacklists,wikis,email_blocklist_title,email_blocklist_graph,graph_folder,graph_suffix\n",
    "\n",
    "## \n",
    "\n",
    "email_blacklists = data.table(email_blacklists);\n",
    "email_blacklists[, log_date := as.Date(log_date)];\n",
    "\n",
    "dates = seq.Date(min(email_blacklists$log_date), max(email_blacklists$log_date), by='month');\n",
    "dates = rbindlist(lapply(wikis, function(w) { data.table(wiki=rep(w, length(dates)), log_date=dates)}))\n",
    "\n",
    "email_blacklists = merge(dates, email_blacklists, on = c('wiki', 'log_date'), all.x = TRUE);\n",
    "email_blacklists[is.na(num_events), num_events := 0];\n",
    "\n",
    "graphs = make_graphs(email_blacklists, wikis, email_blocklist_title, email_blocklist_graph,\n",
    "                     graph_folder, graph_suffix);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graphs, I was concerned about the spike in usage for July 2018. We discussed in the team whether it was initial usage or not, but after digging further and adding some additional clauses to the SQL query (e.g. the check for ID 0 and an empty quoted string), the cleaner data did not contain this spike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users who add their first user to the Echo notification block list\n",
    "\n",
    "Same approach as for the email blacklist, except the property is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_blacklist_query = '''\n",
    "SELECT wiki,\n",
    "       DATE_FORMAT(first_event, \"%Y-%m-01\") AS log_date,\n",
    "       COUNT(*) AS num_events\n",
    "FROM (SELECT wiki, user_id, MIN(timestamp) AS first_event\n",
    "      FROM ((\n",
    "        SELECT wiki,\n",
    "               event_userid AS user_id,\n",
    "               MIN(timestamp COLLATE utf8_unicode_ci) AS timestamp\n",
    "        FROM log.{tables[0]}\n",
    "        WHERE timestamp >= \"{data_timestamp}\"\n",
    "        AND timestamp < \"{end_timestamp}\"\n",
    "        AND wiki IN ({wiki_list})\n",
    "        AND event_property = \"echo-notifications-blacklist\"\n",
    "        AND event_value != \"null\"\n",
    "        AND event_value != '\"0\"'\n",
    "        AND event_value != '\"\"'\n",
    "        GROUP BY wiki, user_id\n",
    "    )\n",
    "    UNION ALL\n",
    "    (\n",
    "        SELECT wiki,\n",
    "               event_userid AS user_id,\n",
    "               MIN(timestamp) AS timestamp\n",
    "        FROM log.{tables[1]}\n",
    "        WHERE timestamp >= \"{data_timestamp}\"\n",
    "        AND timestamp < \"{end_timestamp}\"\n",
    "        AND wiki IN ({wiki_list})\n",
    "        AND event_property = \"echo-notifications-blacklist\"\n",
    "        AND event_value != \"null\"\n",
    "        AND event_value != '\"0\"'\n",
    "        AND event_value != '\"\"'\n",
    "        GROUP BY wiki, user_id\n",
    "    )) AS e\n",
    "    GROUP BY wiki, user_id) AS ev\n",
    "WHERE first_event >= \"{start_timestamp}\"\n",
    "AND first_event < \"{end_timestamp}\"\n",
    "GROUP BY wiki, log_date\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_blacklists = mariadb.run(echo_blacklist_query.format(\n",
    "    tables = log_tables,\n",
    "    data_timestamp = start_time.replace(year=start_time.year-1).strftime(mw_format),\n",
    "    start_timestamp = start_time.strftime(mw_format),\n",
    "    end_timestamp = end_time.strftime(mw_format),\n",
    "    wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis])\n",
    "    ), host='logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i echo_blacklists,wikis,echo_blocklist_title,echo_blocklist_graph,graph_folder,graph_suffix,echo_start_time\n",
    "\n",
    "## \n",
    "\n",
    "echo_blacklists = data.table(echo_blacklists);\n",
    "echo_blacklists[, log_date := as.Date(log_date)];\n",
    "\n",
    "dates = seq.Date(min(echo_blacklists$log_date), max(echo_blacklists$log_date), by='month');\n",
    "dates = rbindlist(lapply(wikis, function(w) { data.table(wiki=rep(w, length(dates)), log_date=dates)}))\n",
    "\n",
    "echo_blacklists = merge(dates, echo_blacklists, on = c('wiki', 'log_date'), all.x = TRUE);\n",
    "echo_blacklists[is.na(num_events), num_events := 0];\n",
    "\n",
    "graphs = make_graphs(\n",
    "    echo_blacklists[log_date >= echo_start_time],\n",
    "    wikis, echo_blocklist_title, echo_blocklist_graph, graph_folder, graph_suffix);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, due to how I am looking for the first event where the list contained something, I suspect that this data quality issue does not affect this data. The spikes that show up in the graphs can be explained as the feature being launched and lots of users making their first changes.\n",
    "\n",
    "That being said, we're interested in the development of the graph over time, something that spike hides because the magnitude of later changes is diminished. We are also perhaps more interested in recent development relative to initial adoption. As a result, I choose to change the start date of these graphs from the beginning of the data we have to 2018-01-01, which removes the spike.\n",
    "\n",
    "# Snapshot statistics\n",
    "\n",
    "We are interested in understanding to what extent users have the same usernames on both the email and Echo notification block lists. Secondly, we want to know more about how many usernames are on the list, either as a graph of the distribution or some summary statistics. Let's tackle the list similarity measurement first.\n",
    "\n",
    "For these measurements, we use whatever data is available in the replicated MediaWiki databases when the queries were run. Currently that's 2019-03-11.\n",
    "\n",
    "## List similarity\n",
    "\n",
    "I first ran a couple of queries to understand what values exists in the database, in this case I used the English Wikipedia as my test wiki:\n",
    "\n",
    "```mysql\n",
    "SELECT SUM(IF(up_value IS NULL, 1, 0)) AS num_is_null,\n",
    "SUM(IF(up_value = \"\", 1, 0)) AS num_empty_string,\n",
    "SUM(IF(up_value IS NOT NULL AND up_value != '', 1, 0)) AS num_set\n",
    "FROM user_properties\n",
    "WHERE up_property= 'echo-notifications-blacklist';\n",
    "       \n",
    "SELECT SUM(IF(up_value IS NULL, 1, 0)) AS num_is_null,\n",
    "SUM(IF(up_value = \"\", 1, 0)) AS num_empty_string,\n",
    "SUM(IF(up_value IS NOT NULL AND up_value != '', 1, 0)) AS num_set\n",
    "FROM user_properties\n",
    "WHERE up_property= 'email-blacklist';\n",
    "```\n",
    "\n",
    "Here, I found that no user has it set to `NULL`. A lot of users has it set to an empty string, whereas a lot fewer users has it set. For email, 58,016 users has it set to an empty string, while only 196 users has it set to something else. For Echo notifications, 5,520 users has it set to an empty string, while 956 users has it set to something else.\n",
    "\n",
    "This suggests that if we simply did straight comparisons, we might get a lot of false positives in that a user will have both set to an empty string. In this case, based on the phrasing of the question, I'll interpret having an empty string as out of scope. In other words, we're measuring the size of the intersection between both lists in the case that either list is empty.\n",
    "\n",
    "Further inspection of how `up_value` is set, it appears that these are unsorted lists, meaning that we need to split and sort them to properly compare their equality, as it's not clear that the list will be identical in both cases. (**NOTE:** Further inspection of the data suggests that this assumption might be wrong and that direct comparison is possible, it just wasn't obvious that the list is sorted. However, on English Wikipedia the set comparison method return 15 users, while direct comparison only returns 13.) That means we'll grab the data for all users and process it individually outside of MariaDB, as its support for splitting strings and such appears to be non-existent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropUser:\n",
    "    def __init__(self, user_id, email_set, echo_set):\n",
    "        self.user_id = user_id\n",
    "        self.email_set = email_set\n",
    "        self.echo_set = echo_set\n",
    "        \n",
    "    def is_equal(self):\n",
    "        '''\n",
    "        The sets are equal if the intersection is the same length as the union.\n",
    "        '''\n",
    "        ## If either of them are not set, we return false\n",
    "        if(len(self.email_set) == 0 or len(self.echo_set) == 0):\n",
    "            return(False)\n",
    "\n",
    "        return(len(self.email_set & self.echo_set) == len(self.email_set | self.echo_set))\n",
    "    \n",
    "    def one_set(self):\n",
    "        '''\n",
    "        Does the user have at least one user on either of their lists?        \n",
    "        '''\n",
    "        \n",
    "        if(len(self.email_set) > 0):\n",
    "            return(True)\n",
    "        \n",
    "        if(len(self.echo_set) > 0):\n",
    "            return(True)\n",
    "        \n",
    "        return(False)\n",
    "\n",
    "def calc_intersection(wiki, db_mapping,\n",
    "                      email_prop = 'email-blacklist', echo_prop = 'echo-notifications-blacklist'):\n",
    "    '''\n",
    "    Calculate the proportion of users in the given wiki who have the same set of usernames in\n",
    "    their email block list (`email_prop`) and Echo notifications block list (`echo_prop`).\n",
    "    '''\n",
    "    \n",
    "    ## Query to retrieve user id and preference value for a given property where\n",
    "    ## the value cannot be NULL nor an empty string\n",
    "    prop_query = '''\n",
    "    SELECT up_user, up_value\n",
    "    FROM user_properties\n",
    "    WHERE up_property = %s\n",
    "    AND up_value IS NOT NULL\n",
    "    AND up_value != \"\"\n",
    "    '''\n",
    "    \n",
    "    ## Mapping of user ID to the PropUser object\n",
    "    id_user_map = {}\n",
    "           \n",
    "    # connect to the database\n",
    "    wiki_hostport = get_dbstore_host_port(db_mapping, False, wiki)\n",
    "    wiki_dbconn = pymysql.connect(\n",
    "        host = wiki_hostport[0],\n",
    "        port = wiki_hostport[1],\n",
    "        db= wiki,\n",
    "        read_default_file = '/etc/mysql/conf.d/research-client.cnf',\n",
    "        charset = 'utf8'\n",
    "    )\n",
    "    \n",
    "    # grab all users who have email_prop set and process them\n",
    "    with wiki_dbconn.cursor() as db_cursor:\n",
    "        db_cursor.execute(prop_query,\n",
    "                          (email_prop))\n",
    "        for (user_id, prop_value) in db_cursor:\n",
    "            prop_value = prop_value.decode('utf-8')\n",
    "            props = set(prop_value.strip().split('\\n'))\n",
    "            id_user_map[user_id] = PropUser(user_id, props, set())\n",
    "    \n",
    "    # grab all users who have echo_prop set and process them\n",
    "    with wiki_dbconn.cursor() as db_cursor:\n",
    "        db_cursor.execute(prop_query,\n",
    "                          (echo_prop))\n",
    "        for (user_id, prop_value) in db_cursor:\n",
    "            prop_value = prop_value.decode('utf-8')\n",
    "            props = set(prop_value.strip().split('\\n'))\n",
    "            \n",
    "            if(user_id in id_user_map):\n",
    "                user = id_user_map[user_id]\n",
    "                user.echo_set = props\n",
    "            else:\n",
    "                id_user_map[user_id] = PropUser(user_id, set(), props)\n",
    "\n",
    "    num_users = len([u for u in id_user_map.values() if u.one_set()])\n",
    "    num_equal = len([u for u in id_user_map.values() if u.is_equal()])\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Wiki: {}\n",
    "    Number of users with at least one value set: {}\n",
    "    Number of users with both sets equal: {}\n",
    "    Percentage: {}\n",
    "    \"\"\".format(wiki, num_users, num_equal, 100*num_equal/num_users))\n",
    "                \n",
    "    wiki_dbconn.close()\n",
    "    return(id_user_map)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Wiki: enwiki\n",
      "    Number of users with at least one value set: 1117\n",
      "    Number of users with both sets equal: 15\n",
      "    Percentage: 1.3428827215756491\n",
      "    \n",
      "\n",
      "    Wiki: frwiki\n",
      "    Number of users with at least one value set: 164\n",
      "    Number of users with both sets equal: 1\n",
      "    Percentage: 0.6097560975609756\n",
      "    \n",
      "\n",
      "    Wiki: dewiki\n",
      "    Number of users with at least one value set: 500\n",
      "    Number of users with both sets equal: 3\n",
      "    Percentage: 0.6\n",
      "    \n",
      "\n",
      "    Wiki: eswiki\n",
      "    Number of users with at least one value set: 209\n",
      "    Number of users with both sets equal: 2\n",
      "    Percentage: 0.9569377990430622\n",
      "    \n",
      "\n",
      "    Wiki: ruwiki\n",
      "    Number of users with at least one value set: 142\n",
      "    Number of users with both sets equal: 4\n",
      "    Percentage: 2.816901408450704\n",
      "    \n",
      "\n",
      "    Wiki: itwiki\n",
      "    Number of users with at least one value set: 71\n",
      "    Number of users with both sets equal: 0\n",
      "    Percentage: 0.0\n",
      "    \n",
      "\n",
      "    Wiki: nlwiki\n",
      "    Number of users with at least one value set: 54\n",
      "    Number of users with both sets equal: 1\n",
      "    Percentage: 1.8518518518518519\n",
      "    \n",
      "\n",
      "    Wiki: jawiki\n",
      "    Number of users with at least one value set: 151\n",
      "    Number of users with both sets equal: 4\n",
      "    Percentage: 2.6490066225165565\n",
      "    \n",
      "\n",
      "    Wiki: zhwiki\n",
      "    Number of users with at least one value set: 174\n",
      "    Number of users with both sets equal: 3\n",
      "    Percentage: 1.7241379310344827\n",
      "    \n",
      "\n",
      "    Wiki: ptwiki\n",
      "    Number of users with at least one value set: 99\n",
      "    Number of users with both sets equal: 0\n",
      "    Percentage: 0.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for wiki in wikis:\n",
    "    calc_intersection(wiki, wikidb_map)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For verification, I wrote a query to directy compare values and noticed that\n",
    "it resulted in the same results as I got using the other method, except for English Wikipedia,\n",
    "where the set comparison method correctly identifies two users who have lists that are the same\n",
    "but in different order.\n",
    "\n",
    "'''\n",
    "SELECT *\n",
    "FROM (SELECT * FROM user_properties WHERE up_property = 'email-blacklist') AS up1\n",
    "JOIN (SELECT * FROM user_properties WHERE up_property = 'echo-notifications-blacklist') AS up2\n",
    "ON up1.up_user = up2.up_user\n",
    "AND up1.up_value = up2.up_value\n",
    "WHERE up1.up_value != \"\"\n",
    "AND up2.up_value != \"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List distribution\n",
    "\n",
    "Here, we'll get the list for each user, decode it and turn it into a number. This can all be done in Pandas, I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_prop_list(x):\n",
    "    if(x == \"\"):\n",
    "        return(0)    \n",
    "    return(len(x.strip().split('\\n')))\n",
    "\n",
    "def get_prop_dist(wiki, db_mapping, prop_name):\n",
    "    '''\n",
    "    For the given wiki, connect to the replicated database and grab all users with the given property\n",
    "    set. Then return a `pandas.DataFrame` with user IDs and the length of their list.\n",
    "    '''\n",
    "    \n",
    "    prop_query = '''\n",
    "    SELECT up_user, up_value\n",
    "    FROM user_properties\n",
    "    WHERE up_property = \"{}\"\n",
    "    AND up_value IS NOT NULL\n",
    "    '''\n",
    "    \n",
    "    # connect to the database\n",
    "    wiki_hostport = get_dbstore_host_port(db_mapping, False, wiki)\n",
    "    wiki_dbconn = pymysql.connect(\n",
    "        host = wiki_hostport[0],\n",
    "        port = wiki_hostport[1],\n",
    "        db= wiki,\n",
    "        read_default_file = '/etc/mysql/conf.d/research-client.cnf',\n",
    "        charset = 'utf8'\n",
    "    )\n",
    "    \n",
    "    user_data = pd.read_sql_query(prop_query.format(prop_name), wiki_dbconn)\n",
    "    user_data = user_data.applymap(try_decode).rename(columns = try_decode)\n",
    "    user_data['n_users'] = user_data['up_value'].apply(len_prop_list)\n",
    "    user_data = user_data.drop('up_value', axis = 1)\n",
    "    user_data['wiki'] = wiki\n",
    "    \n",
    "    wiki_dbconn.close()\n",
    "    \n",
    "    return(user_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_usage = pd.concat([get_prop_dist(w, wikidb_map, 'email-blacklist') for w in wikis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_usage = pd.concat([get_prop_dist(w, wikidb_map, 'echo-notifications-blacklist') for w in wikis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "make_histograms = function(dt, wikis, title, filename, graph_dir, graph_suffix) {\n",
    "    graphs = c()\n",
    "    for(w in wikis) {\n",
    "        g = ggplot(dt[wiki == w & n_users > 0], aes(x = n_users)) +\n",
    "        labs(title = paste0(title, w),\n",
    "             x = 'Number of users on the list',\n",
    "             y = 'Count') +\n",
    "        theme_light(base_size = 14) +\n",
    "        geom_histogram(binwidth = 1);\n",
    "        ggsave(paste0(graph_dir, filename, '_', w, graph_suffix),\n",
    "               plot = g, width = 30, height = 20, units = \"cm\", dpi = \"screen\");\n",
    "        graphs = append(graphs, g);\n",
    "    }\n",
    "    graphs;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i email_usage,email_usage_graph,email_usage_title,wikis,graph_folder,graph_suffix\n",
    "\n",
    "graphs = make_histograms(data.table(email_usage), wikis, email_usage_title, email_usage_graph,\n",
    "                graph_folder, graph_suffix);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i echo_usage,echo_usage_graph,echo_usage_title,wikis,graph_folder,graph_suffix\n",
    "\n",
    "graphs = make_histograms(data.table(echo_usage), wikis, echo_usage_title, echo_usage_graph,\n",
    "                graph_folder, graph_suffix);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
